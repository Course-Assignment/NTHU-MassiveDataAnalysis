{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Massive Data Analysis Term Project -- Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "109062623 林鎰鋒 Group51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from operator import itemgetter\n",
    "from math import sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"RecommendationSystem\") \\\n",
    "                .setMaster(\"local[*]\") \\\n",
    "\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Read and process the dataset \n",
    "\n",
    "`\n",
    "610 users, 9742 movies, ~100k rating record\n",
    "(userId, movieId, rating, timestamp)\n",
    "`\n",
    "\n",
    "From MovieLens: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movie_as_key (map)\n",
    "Transform data as follow\n",
    "\n",
    "`\n",
    "(movieId, (userId, rating))\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_as_key(x):\n",
    "    x = x.split(\",\")\n",
    "    return (int(x[1]), (int(x[0]), float(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = sc.textFile(\"ratings_minimal.csv\")\n",
    "header = raw_data.first()\n",
    "\n",
    "data = raw_data.filter(lambda line: line != header) \\\n",
    "        .map(movie_as_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-item Collaborative Filtering\n",
    "Output Result: https://www.dropbox.com/s/ao53hl6rfkbwl4p/similarity.out?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract Mean & Norm\n",
    "Caculate the substract mean and norm for each movie item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### total_sum\n",
    "Get the sum of user rating for each movie\n",
    "\n",
    "#### total_count\n",
    "Get the number of user rating for each movie\n",
    "\n",
    "#### mean\n",
    "Caculate the mean user rating of each movie\n",
    "\n",
    "#### subtract_mean (map)\n",
    "Calculate the subtract mean, and transform data as follow\n",
    "\n",
    "`\n",
    "(movie_k, (userId, rating - mean of movie_k))\n",
    "`\n",
    "\n",
    "#### caculate_norm (map)\n",
    "Transform data as follow, and calculate the norm\n",
    "\n",
    "`\n",
    "(movie_k, (norm_k, [(user_1, rating_1k), (user_2, rating_2k), ... , (user_i, rating_ik)]))\n",
    "rating_ij -> (movie_i, user_j)\n",
    "`\n",
    "\n",
    "#### user_as_key (map)\n",
    "Transform data as follow\n",
    "\n",
    "`\n",
    "(userId, (movieId, subtract_mean_rating, movie_norm))\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_mean(x):\n",
    "    ((user, rating), mean) = x\n",
    "    return (user, rating - mean)\n",
    "\n",
    "def caculate_norm(rating_list):\n",
    "    return (sqrt(sum([rating[1] ** 2 for rating in rating_list])), rating_list)\n",
    "\n",
    "def user_as_key(x):\n",
    "    ((movie, norm), (user, rating)) = x\n",
    "    return (user, (movie, rating, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = data.map(lambda x: (x[0], x[1][1])) \\\n",
    "                .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "total_count = data.map(lambda x: (x[0], x[1][1])) \\\n",
    "                .groupByKey() \\\n",
    "                .mapValues(len)\n",
    "\n",
    "mean = total_sum.join(total_count) \\\n",
    "            .mapValues(lambda x: x[0]/x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = data.join(mean) \\\n",
    "    .mapValues(subtract_mean) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(caculate_norm) \\\n",
    "    .map(lambda x: ((x[0], x[1][0]), x[1][1])) \\\n",
    "    .flatMapValues(lambda x: x) \\\n",
    "    .map(user_as_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "Caculate the \"Cosine Similarity\" for each movie item pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter_duplicates\n",
    "Join the all movie item to get all possible movie item pairs and drop all duplicate movie item pairs by filter_duplicates()\n",
    "\n",
    "`\n",
    "((movie1, rating1, norm1), (movie2, rating2, norm2))\n",
    "`\n",
    "\n",
    "#### make_pairs (map)\n",
    "Transform data as follow\n",
    "\n",
    "`\n",
    "((movie1, rating1, norm1), (movie2, rating2, norm2)) -> ((movie1, movie2), ((rating1, norm1), (rating2, norm2)))\n",
    "`\n",
    "\n",
    "#### caculate_dot_product (map)\n",
    "After groupByKey() we get structure as follow, then we caculate the dot product of the movie item pairs by their user rating which rating by same user\n",
    "\n",
    "`\n",
    "((movie1, movie2), [((rating_11, norm1), (rating_21, norm2)), ((rating_12, norm1), (rating_22, norm2)), ...])\n",
    "rating_ij -> (movie_i, user_j)\n",
    "`\n",
    "#### caculate_cosine_similarity (map)\n",
    "Here, each movie item pairs, we got both dot product and their self norm.\n",
    "\n",
    "Then, we caculate the cosine similarity for each movie item pairs.\n",
    "\n",
    "Finally, we got data as follow.\n",
    "\n",
    "`\n",
    "((movie_i, movie_j), similarity_ij)\n",
    "`\n",
    "\n",
    "Ps. if two movie items' norm is both 0, then we set the cosine similarity as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duplicates(user_ratings):\n",
    "    ratings = user_ratings[1]\n",
    "    (movie1, rating1, norm1) = ratings[0]\n",
    "    (movie2, rating2, norm2) = ratings[1]\n",
    "    return movie1 < movie2\n",
    "\n",
    "def make_pairs(user_ratings):\n",
    "    ratings = user_ratings[1]\n",
    "    (movie1, rating1, norm1) = ratings[0]\n",
    "    (movie2, rating2, norm2) = ratings[1]\n",
    "    return ((movie1, movie2), ((rating1, norm1), (rating2, norm2)))\n",
    "\n",
    "def caculate_dot_product(rating_pairs):\n",
    "    dot_product = 0\n",
    "    for (rating1, norm1), (rating2, norm2) in rating_pairs:\n",
    "        dot_product += rating1 * rating2\n",
    "    return (dot_product, norm1, norm2)\n",
    "    \n",
    "def caculate_cosine_similarity(x):\n",
    "    (dot_product, norm1, norm2) = x\n",
    "    if (norm1 != 0 and norm2 != 0):\n",
    "        return dot_product / (norm1 * norm2)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = item.join(item) \\\n",
    "    .filter(filter_duplicates) \\\n",
    "    .map(make_pairs) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(caculate_dot_product) \\\n",
    "    .mapValues(caculate_cosine_similarity) \\\n",
    "    .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = similarity.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"similarity.out\", result, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Predictions\n",
    "Select top 10 similarity to calculate the movie rating for each user\n",
    "\n",
    "Output Result: https://www.dropbox.com/s/wtcogl0lv1fxx7n/predict.out?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movie_all, user_predict, user_rating\n",
    "Used to create (user, movie) pair which need to predict\n",
    "`\n",
    "user_predict -> (user, movie)\n",
    "user_rating  -> (user, (movie, rating)\n",
    "`\n",
    "\n",
    "#### item_pair = user_predict.join(user_rating)\n",
    "Join the users which want to predict with other movie which also rating by them. And transform data as follow\n",
    "\n",
    "`\n",
    "item_pair -> ((movie_i, movie_j), (movie_i, user_k, rating_jk))\n",
    "`\n",
    "\n",
    "#### item_pair.join(similarity)\n",
    "Join the item pair with their similarity\n",
    "`\n",
    "((movie_i, movie_j), (movie_i, user_k, rating_jk)) join ((movie_i, movie_j), similarity_ij) ->\n",
    "((movie_i, movie_j), ((movie_i, user_k, rating_jk), similarity_ij)\n",
    "`\n",
    "\n",
    "#### rating_predictions_top_10 (map)\n",
    "Calculate the movie's rating by top 10 similarity movies' user rating\n",
    "\n",
    "If the similarity in top 10 is less or equal to zero than drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_predictions_top_10(x):\n",
    "    numerator = denominator = counter = 0\n",
    "    x = list(x)\n",
    "    x.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    for (rating, similarity) in x:\n",
    "        if(counter == 10 or similarity <= 0): break\n",
    "        numerator += (similarity * rating)\n",
    "        denominator += similarity\n",
    "        counter += 1\n",
    "      \n",
    "    if(denominator == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = sc.broadcast(data.map(lambda x: (x[1][0], (x[0], x[1][1]))) \\\n",
    "                        .groupByKey() \\\n",
    "                        .keys() \\\n",
    "                        .collect())\n",
    "\n",
    "movie = data.map(lambda x: (x[0], x[1][0])) \\\n",
    "            .groupByKey() \\\n",
    "            .mapValues(list) \\\n",
    "            .flatMapValues(lambda x: x)\n",
    "\n",
    "movie_all = data.groupByKey() \\\n",
    "            .keys() \\\n",
    "            .map(lambda x: (x, user.value)) \\\n",
    "            .flatMapValues(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predict = movie_all.subtract(movie) \\\n",
    "                        .map(lambda x: (x[1], x[0])) \\\n",
    "\n",
    "user_rating = data.map(lambda x: (x[1][0], (x[0], x[1][1]))) \\\n",
    "                .groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pair = user_predict.join(user_rating) \\\n",
    "                .map(lambda x: ((x[0], x[1][0]), x[1][1])) \\\n",
    "                .flatMapValues(lambda x: x) \\\n",
    "                .map(lambda x: ((x[0][1], x[1][0]), (x[0][1], x[0][0], x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = item_pair.join(similarity) \\\n",
    "                    .map(lambda x: ((x[1][0][1], x[1][0][0]), (x[1][0][2], x[1][1]))) \\\n",
    "                    .groupByKey() \\\n",
    "                    .mapValues(rating_predictions_top_10) \\\n",
    "                    .filter(lambda x: x[1] > 0) \\\n",
    "                    .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prediction.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"predict.out\", result, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
